{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import numpy.linalg\n",
    "import numpy.matlib\n",
    "from numpy.linalg import norm\n",
    "import algorithms.trend_filter_R as tfilterR\n",
    "import algorithms.trend_filter as tfilter\n",
    "\n",
    "from scipy import interpolate\n",
    "from scipy import signal\n",
    "import csv   \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "full_lcurve() got an unexpected keyword argument 'lambda_min'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5e7a5cd09202>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m#L-CURVE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mtf_flc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_lcurve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlambda_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlambda_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_lambdas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_lambdas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mtf_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_flc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_flc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: full_lcurve() got an unexpected keyword argument 'lambda_min'"
     ]
    }
   ],
   "source": [
    "# LOAD DATA\n",
    "\n",
    "# 1) LOAD DYNAMICS AND TIME ARRAYS\n",
    "\n",
    "filepath = 'data_files/Lorenz63_dynamics.csv'\n",
    "dynamics = np.genfromtxt(filepath, delimiter=',')\n",
    "\n",
    "t = dynamics[0]\n",
    "data = dynamics[1:]\n",
    "n_states = int(data.shape[0] / 2)\n",
    "X = data[0:n_states]\n",
    "DX = data[n_states:]\n",
    "t_samples = len(t)\n",
    "\n",
    "noise_lvl = 0.001\n",
    "\n",
    "write_data = True\n",
    "\n",
    "## Select realization\n",
    "sample = 0\n",
    "\n",
    "##Range of lambdas\n",
    "lambda_min = 1e-16\n",
    "lambda_max = 100\n",
    "n_lambdas = 100\n",
    "\n",
    "#Vreate dictionary to store values\n",
    "lcurve_dict = {}\n",
    "gcv_dict = {}\n",
    "\n",
    "\n",
    "# LOAD OBSERVATION SAMPLES\n",
    "Y_samples = []\n",
    "\n",
    "for state in range(n_states):\n",
    "\n",
    "    filepath = 'data_files/Lorenz63_samples_noise_' + str(noise_lvl) +'_Y'+ str(state+1) + '.csv'\n",
    "    y = np.genfromtxt(filepath, delimiter=',')\n",
    "\n",
    "    Y_samples.append(y)\n",
    "\n",
    "n_samples = Y_samples[0].shape[0]\n",
    "\n",
    "################### DENOISING AND NUMERICAL DIFFERENTIATION - SMOOTHING SPLINES ###################\n",
    "# trim = int(np.floor(5 / 100 * t_samples))\n",
    "# tt_samples = t_samples - 2 * trim\n",
    "\n",
    "\n",
    "for state in range(n_states):\n",
    "\n",
    "    y = Y_samples[state][sample,:]\n",
    "\n",
    "    #GCV\n",
    "    #tf_gcv = tfilterR.gcv(y, order = 3, lambda_min = lambda_min, lambda_max = lambda_max, n_lambdas = n_lambdas)\n",
    "    tf_gcv = tfilterR.gcv(y, t, order = 3)\n",
    "    lambdas, gcv_lambda = tf_gcv[1]\n",
    "    min_gcv_indx = np.argmin(gcv_lambda)\n",
    "    min_gcv = np.min(gcv_lambda)\n",
    "    min_gcv_lambda = lambdas[min_gcv_indx] \n",
    "\n",
    "    y_tf_path = tf_gcv[2]\n",
    "\n",
    "    error_path_gcv = np.zeros(y_tf_path.shape[1])\n",
    "    for i in range(y_tf_path.shape[1]):\n",
    "        error_path_gcv[i] = norm(y_tf_path[:,i] - X[state,:]) / norm(X[state,:])\n",
    "    min_indx_error_gcv = np.argmin(error_path_gcv) \n",
    "    min_error_gcv_gcv = gcv_lambda[min_indx_error_gcv]\n",
    "    min_error_gcv_lambda = lambdas[min_indx_error_gcv]\n",
    "\n",
    "    #Solve for optimal gcv lambda\n",
    "    tf_gcv_opt = tfilter.trend_filter(y, lambd = min_gcv_lambda, order = 3)\n",
    "    res_gcv, reg_gcv = tf_gcv_opt[1]\n",
    "    \n",
    "    lambda_min = np.min(lambdas)\n",
    "    lambda_max = np.max(lambdas)\n",
    "    \n",
    "    #L-CURVE\n",
    "    tf_flc = tfilter.full_lcurve(y, order = 3, lambda_min = lambda_min, lambda_max = lambda_max, n_lambdas = n_lambdas)\n",
    "    tf_path = tf_flc[0]\n",
    "    res, reg = tf_flc[1]\n",
    "    error_path = np.zeros(tf_path.shape[1])\n",
    "    for i in range(tf_path.shape[1]):\n",
    "        error_path[i] = norm(tf_path[:,i] - X[state,:]) / norm(X[state,:])\n",
    "\n",
    "    min_indx_lc = np.argmin(error_path)\n",
    "    res_min = res[min_indx_lc]\n",
    "    reg_min = reg[min_indx_lc]\n",
    "\n",
    "    #Find corner point\n",
    "    tf_lc = tfilter.lcurve_corner(y, order = 3, lambda_min = lambda_min, lambda_max = lambda_max)\n",
    "    tf_lc = tfilter.lcurve_corner(y, t, order = 3)\n",
    "    y_tf = tf_lc[0]\n",
    "    res_lc, reg_lc = tf_lc[3]\n",
    "    lambda_lc = tf_lc[1]\n",
    "\n",
    "    #Solve for optimal Lcurve lambda\n",
    "    tf_lc_opt = tfilter.trend_filter(y, lambd = lambda_lc, order = 3)\n",
    "    gcv_lc = tf_lc_opt[2][0]\n",
    "\n",
    "\n",
    "    plt.figure(figsize = (16,8))\n",
    "    plt.loglog(res, reg)\n",
    "    plt.loglog(res_min, reg_min,'ko')\n",
    "    plt.loglog(res_lc[-1], reg_lc[-1], 'ro')\n",
    "    plt.loglog(res_gcv, reg_gcv, 'bo')\n",
    "\n",
    "    lcurve_dict[f'state{state+1}:residual'] = res.tolist()\n",
    "    lcurve_dict[f'state{state+1}:regularizer'] = reg.tolist()\n",
    "    lcurve_dict[f'state{state+1}:res_corner'] = res_lc[-1]\n",
    "    lcurve_dict[f'state{state+1}:reg_corner'] = reg_lc[-1]\n",
    "    lcurve_dict[f'state{state+1}:res_min'] = res_min\n",
    "    lcurve_dict[f'state{state+1}:reg_min'] = reg_min\n",
    "    lcurve_dict[f'state{state+1}:res_gcv'] = res_gcv\n",
    "    lcurve_dict[f'state{state+1}:reg_gcv'] = reg_gcv\n",
    "\n",
    "    plt.figure(figsize = (16,8))\n",
    "    plt.semilogx(lambdas, gcv_lambda)\n",
    "    plt.semilogx(min_gcv_lambda, min_gcv, 'bo')\n",
    "    plt.semilogx(min_error_gcv_lambda, min_error_gcv_gcv, 'ko')\n",
    "    plt.semilogx(lambda_lc, gcv_lc, 'ro')\n",
    "\n",
    "    gcv_dict[f'state{state+1}:lambdas'] = lambdas.tolist()\n",
    "    gcv_dict[f'state{state+1}:gcv_func'] = gcv_lambda.tolist()\n",
    "    gcv_dict[f'state{state+1}:lambda_lcurve'] = lambda_lc.tolist()\n",
    "    gcv_dict[f'state{state+1}:gcv_lcurve'] = gcv_lc.tolist()\n",
    "    gcv_dict[f'state{state+1}:min_error_lambda'] = min_error_gcv_lambda\n",
    "    gcv_dict[f'state{state+1}:min_error_gcv'] = min_error_gcv_gcv\n",
    "    gcv_dict[f'state{state+1}:min_lambda'] = min_gcv_lambda\n",
    "    gcv_dict[f'state{state+1}:min_gcv'] = min_gcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if write_data:\n",
    "    # STORE LCURVE IN JSON FORMAT\n",
    "    filename_lc = 'Lorenz63_trendfilter_lcurve_noise_' + str(noise_lvl).replace('.','d') + '.json'\n",
    "    filepath_lc = 'data_files/trendfilter/' + filename_lc\n",
    "    with open(filepath_lc, \"w\") as outfile:  \n",
    "        json.dump(lcurve_dict, outfile)  \n",
    "\n",
    "    # STORE GCV IN JSON FORMAT\n",
    "    filename_gcv = 'Lorenz63_trendfilter_gcv_noise_' + str(noise_lvl).replace('.','d') + '.json'\n",
    "    filepath_gcv = 'data_files/trendfilter/' + filename_gcv\n",
    "    with open(filepath_gcv, \"w\") as outfile:  \n",
    "        json.dump(gcv_dict, outfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
