{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import numpy.linalg\n",
    "import numpy.matlib\n",
    "from numpy.linalg import norm\n",
    "import algorithms.tikhonov as tikhonov\n",
    "from scipy import interpolate\n",
    "from scipy import signal\n",
    "import csv   \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexandre/anaconda3/lib/python3.7/site-packages/scipy/sparse/linalg/dsolve/linsolve.py:318: SparseEfficiencyWarning: splu requires CSC matrix format\n",
      "  warn('splu requires CSC matrix format', SparseEfficiencyWarning)\n",
      "/home/alexandre/anaconda3/lib/python3.7/site-packages/scipy/sparse/linalg/dsolve/linsolve.py:216: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
      "  'is in the CSC matrix format', SparseEfficiencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: 1 | Realization: 0\n",
      "State: 1 | Realization: 1\n",
      "State: 1 | Realization: 2\n",
      "State: 1 | Realization: 3\n",
      "State: 1 | Realization: 4\n",
      "State: 1 | Realization: 5\n",
      "State: 1 | Realization: 6\n"
     ]
    }
   ],
   "source": [
    "# LOAD DATA\n",
    "\n",
    "# 1) LOAD DYNAMICS AND TIME ARRAYS\n",
    "\n",
    "filepath = 'data_files/VanderPol_dynamics.csv'\n",
    "dynamics = np.genfromtxt(filepath, delimiter=',')\n",
    "\n",
    "t = dynamics[0]\n",
    "data = dynamics[1:]\n",
    "n_states = int(data.shape[0] / 2)\n",
    "X = data[0:n_states]\n",
    "DX = data[n_states:]\n",
    "t_samples = len(t)\n",
    "\n",
    "# noise_lvls = [0.001, 0.01, 0.1, 1, 2]\n",
    "noise_lvls = [0.0001]\n",
    "\n",
    "n_noise_lvls = len(noise_lvls)\n",
    "\n",
    "mean_X_error = np.zeros((n_states, n_noise_lvls))\n",
    "mean_dX_error = np.zeros((n_states, n_noise_lvls))\n",
    "\n",
    "var_X_error = np.zeros((n_states, n_noise_lvls))\n",
    "var_dX_error = np.zeros((n_states, n_noise_lvls))  \n",
    "\n",
    "for noise, sigma in enumerate(noise_lvls):\n",
    "\n",
    "    # 2) LOAD OBSERVATION SAMPLES\n",
    "    Y_samples = []\n",
    "    noise_lvl = str(sigma)\n",
    "\n",
    "    for state in range(n_states):\n",
    "\n",
    "        filepath = 'data_files/VanderPol_samples_noise_' + noise_lvl +'_Y'+ str(state+1) + '.csv'\n",
    "        y = np.genfromtxt(filepath, delimiter=',')\n",
    "\n",
    "        Y_samples.append(y)\n",
    "\n",
    "    n_samples = Y_samples[0].shape[0]\n",
    "\n",
    "    ################### DENOISING AND NUMERICAL DIFFERENTIATION - SMOOTHING SPLINES ###################\n",
    "    trim = int(np.floor(5 / 100 * t_samples))\n",
    "    error_X = np.zeros((n_samples,n_states))\n",
    "    error_dX = np.zeros((n_samples,n_states))\n",
    "    tt_samples = t_samples - 2 * trim\n",
    "    Yhat_tik = np.zeros((n_samples, tt_samples))\n",
    "    DYhat_tik = np.zeros((n_samples, tt_samples))\n",
    "\n",
    "    for state in range(n_states):\n",
    "\n",
    "        for sample in range(n_samples):#n_samples\n",
    "            \n",
    "            y = Y_samples[state][sample,:]\n",
    "            \n",
    "            #Find optimal lambda through GCV\n",
    "            tik = tikhonov.gcv(y, lambda_min = 1e-8, lambda_max = 100000, n_lambdas = 100, plot_lc = True)\n",
    "            y_tik = tik[0]\n",
    "#             lambdas, gcv = tik[1]\n",
    "\n",
    "            y_tik_ss = interpolate.splrep(t, y_tik, k=3, s=0)\n",
    "            dy_tik = interpolate.splev(t, y_tik_ss, der=1)\n",
    "            \n",
    "            #Remove ends\n",
    "            Yhat_tik[sample,:] = y_tik[trim:-trim]\n",
    "            DYhat_tik[sample,:] = dy_tik[trim:-trim]\n",
    "            \n",
    "            #Compute errors\n",
    "            error_X[sample,state] = norm(Yhat_tik[sample,:] - X[state,trim:-trim]) / norm(X[state,trim:-trim])\n",
    "            error_dX[sample,state] = norm(DYhat_tik[sample,:] - DX[state,trim:-trim]) / norm(DX[state,trim:-trim])\n",
    "            print('State: ' + str(state+1) + ' | ' + 'Realization: ' + str(sample))\n",
    "        filename_y = 'data_files/tikhonov/VanderPol_tikhonov_gcv_' + noise_lvl + '_Y' + str(state+1) + '.csv'\n",
    "        filename_dy = 'data_files/tikhonov/VanderPol_tikhonov_gcv_' + noise_lvl + '_dY' + str(state+1) + '.csv'\n",
    "        with open(filename_y, 'w') as csvfile:   \n",
    "            # creating a csv writer object   \n",
    "            csvwriter = csv.writer(csvfile)   \n",
    "            # writing the data rows   \n",
    "            csvwriter.writerows(Yhat_tik)\n",
    "        with open(filename_dy, 'w') as csvfile:   \n",
    "            # creating a csv writer object   \n",
    "            csvwriter = csv.writer(csvfile)   \n",
    "            # writing the data rows   \n",
    "            csvwriter.writerows(DYhat_tik)\n",
    "\n",
    "        mean_X_error[state, noise] = error_X[:,state].mean()\n",
    "        mean_dX_error[state, noise] = error_dX[:,state].mean()\n",
    "        var_X_error[state, noise] = error_X[:,state].var()\n",
    "        var_dX_error[state, noise] = error_dX[:,state].var()\n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean error x</th>\n",
       "      <th>var. error x</th>\n",
       "      <th>mean error dx</th>\n",
       "      <th>var. error dx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">$\\sigma$ = 0.1</td>\n",
       "      <td>state x1</td>\n",
       "      <td>0.026006</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.101246</td>\n",
       "      <td>0.007197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>state x2</td>\n",
       "      <td>0.015088</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.065295</td>\n",
       "      <td>0.000868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         mean error x  var. error x  mean error dx  \\\n",
       "$\\sigma$ = 0.1 state x1      0.026006      0.000064       0.101246   \n",
       "               state x2      0.015088      0.000014       0.065295   \n",
       "\n",
       "                         var. error dx  \n",
       "$\\sigma$ = 0.1 state x1       0.007197  \n",
       "               state x2       0.000868  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "temp = [['$\\sigma$ = ' + str(x)] * n_states for x in noise_lvls]\n",
    "noise_indx = np.array([item for sublist in temp for item in sublist])\n",
    "\n",
    "state_indx = np.array(['state x' + str(x+1) for x in range(n_states)] * n_noise_lvls)\n",
    "\n",
    "arrays = [noise_indx, state_indx]\n",
    "data = np.vstack((mean_X_error.T.flatten(), var_X_error.T.flatten(), mean_dX_error.T.flatten(), var_dX_error.T.flatten())).T\n",
    "\n",
    "col_names = ['mean error x', 'var. error x', 'mean error dx', 'var. error dx']\n",
    "df = pd.DataFrame(data, index=arrays, columns=col_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cheat sheet\n",
    "\n",
    "#noise = 0.001 -- > lambda_min = 1e-12, lambda_max = 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
