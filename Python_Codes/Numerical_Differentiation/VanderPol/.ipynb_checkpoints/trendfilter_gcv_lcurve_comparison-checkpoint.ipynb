{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import numpy.linalg\n",
    "import numpy.matlib\n",
    "from numpy.linalg import norm\n",
    "import algorithms.trend_filter as tfilter\n",
    "\n",
    "from scipy import interpolate\n",
    "from scipy import signal\n",
    "import csv   \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "data_files/Duffing_dynamics.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e27a3d4953c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data_files/Duffing_dynamics.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdynamics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdynamics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding)\u001b[0m\n\u001b[1;32m   1747\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1748\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1749\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1750\u001b[0m             \u001b[0mfid_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    533\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    534\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: data_files/Duffing_dynamics.csv not found."
     ]
    }
   ],
   "source": [
    "# LOAD DATA\n",
    "\n",
    "# 1) LOAD DYNAMICS AND TIME ARRAYS\n",
    "\n",
    "filepath = 'data_files/Duffing_dynamics.csv'\n",
    "dynamics = np.genfromtxt(filepath, delimiter=',')\n",
    "\n",
    "t = dynamics[0]\n",
    "data = dynamics[1:]\n",
    "n_states = int(data.shape[0] / 2)\n",
    "X = data[0:n_states]\n",
    "DX = data[n_states:]\n",
    "t_samples = len(t)\n",
    "\n",
    "noise_lvl = 0.0001\n",
    "\n",
    "write_data = True\n",
    "\n",
    "## Select realization\n",
    "sample = 0\n",
    "\n",
    "##Range of lambdas\n",
    "lambda_min = 1e-8\n",
    "lambda_max = 10000\n",
    "n_lambdas = 100\n",
    "\n",
    "#Vreate dictionary to store values\n",
    "lcurve_dict = {}\n",
    "gcv_dict = {}\n",
    "\n",
    "\n",
    "# LOAD OBSERVATION SAMPLES\n",
    "Y_samples = []\n",
    "\n",
    "for state in range(n_states):\n",
    "\n",
    "    filepath = 'data_files/VanderPol_samples_noise_' + str(noise_lvl) +'_Y'+ str(state+1) + '.csv'\n",
    "    y = np.genfromtxt(filepath, delimiter=',')\n",
    "\n",
    "    Y_samples.append(y)\n",
    "\n",
    "n_samples = Y_samples[0].shape[0]\n",
    "\n",
    "################### DENOISING AND NUMERICAL DIFFERENTIATION - SMOOTHING SPLINES ###################\n",
    "# trim = int(np.floor(5 / 100 * t_samples))\n",
    "# tt_samples = t_samples - 2 * trim\n",
    "\n",
    "\n",
    "for state in range(n_states):\n",
    "\n",
    "    y = Y_samples[state][sample,:]\n",
    "\n",
    "    #GCV\n",
    "    tf_gcv = tfilter.gcv(y, order = 3, lambda_min = lambda_min, lambda_max = lambda_max, n_lambdas = n_lambdas)\n",
    "    lambdas, gcv_lambda = tf_gcv[1]\n",
    "    min_gcv_indx = np.argmin(gcv_lambda)\n",
    "    min_gcv = np.min(gcv_lambda)\n",
    "    min_gcv_lambda = lambdas[min_gcv_indx] \n",
    "\n",
    "    y_tf_path = tf_gcv[2]\n",
    "\n",
    "    error_path_gcv = np.zeros(y_tf_path.shape[1])\n",
    "    for i in range(y_tf_path.shape[1]):\n",
    "        error_path_gcv[i] = norm(y_tf_path[:,i] - X[state,:]) / norm(X[state,:])\n",
    "    min_indx_error_gcv = np.argmin(error_path_gcv) \n",
    "    min_error_gcv_gcv = gcv_lambda[min_indx_error_gcv]\n",
    "    min_error_gcv_lambda = lambdas[min_indx_error_gcv]\n",
    "\n",
    "    #Solve for optimal gcv lambda\n",
    "    tf_gcv_opt = tfilter.trend_filter(y, lambd = min_gcv_lambda, order = 3)\n",
    "    res_gcv, reg_gcv = tf_gcv_opt[1]\n",
    "    \n",
    "    #L-CURVE\n",
    "    tf_flc = tfilter.full_lcurve(y, order = 3, lambda_min = lambda_min, lambda_max = lambda_max, n_lambdas = n_lambdas)\n",
    "    tf_path = tf_flc[0]\n",
    "    res, reg = tf_flc[1]\n",
    "    error_path = np.zeros(tf_path.shape[1])\n",
    "    for i in range(tf_path.shape[1]):\n",
    "        error_path[i] = norm(tf_path[:,i] - X[state,:]) / norm(X[state,:])\n",
    "\n",
    "    min_indx_lc = np.argmin(error_path)\n",
    "    res_min = res[min_indx_lc]\n",
    "    reg_min = reg[min_indx_lc]\n",
    "\n",
    "    #Find corner point\n",
    "    tf_lc = tfilter.lcurve_corner(y, order = 3, lambda_min = lambda_min, lambda_max = lambda_max)\n",
    "    y_tf = tf_lc[0]\n",
    "    res_lc, reg_lc = tf_lc[3]\n",
    "    lambda_lc = tf_lc[1]\n",
    "\n",
    "    #Solve for optimal Lcurve lambda\n",
    "    tf_lc_opt = tfilter.trend_filter(y, lambd = lambda_lc, order = 3)\n",
    "    gcv_lc = tf_lc_opt[2][0]\n",
    "\n",
    "    plt.figure(figsize = (16,8))\n",
    "    plt.loglog(res, reg)\n",
    "    plt.loglog(res_min, reg_min,'ko')\n",
    "    plt.loglog(res_lc[-1], reg_lc[-1], 'ro')\n",
    "    plt.loglog(res_gcv, reg_gcv, 'bo')\n",
    "\n",
    "    lcurve_dict[f'state{state+1}:residual'] = res.tolist()\n",
    "    lcurve_dict[f'state{state+1}:regularizer'] = reg.tolist()\n",
    "    lcurve_dict[f'state{state+1}:res_corner'] = res_lc[-1]\n",
    "    lcurve_dict[f'state{state+1}:reg_corner'] = reg_lc[-1]\n",
    "    lcurve_dict[f'state{state+1}:res_min'] = res_min\n",
    "    lcurve_dict[f'state{state+1}:reg_min'] = reg_min\n",
    "    lcurve_dict[f'state{state+1}:res_gcv'] = res_gcv\n",
    "    lcurve_dict[f'state{state+1}:reg_gcv'] = reg_gcv\n",
    "    lcurve_dict[f'state{state+1}:lambda_lc'] = lambda_lc\n",
    "    lcurve_dict[f'state{state+1}:gcv_lc'] = gcv_lc\n",
    "\n",
    "    plt.figure(figsize = (16,8))\n",
    "    plt.semilogx(lambdas, gcv_lambda)\n",
    "    plt.semilogx(min_gcv_lambda, min_gcv, 'bo')\n",
    "    plt.semilogx(min_error_gcv_lambda, min_error_gcv_gcv, 'ko')\n",
    "    plt.semilogx(lambda_lc, gcv_lc, 'ro')\n",
    "\n",
    "    gcv_dict[f'state{state+1}:lambdas'] = lambdas.tolist()\n",
    "    gcv_dict[f'state{state+1}:gcv_func'] = gcv_lambda.tolist()\n",
    "    gcv_dict[f'state{state+1}:lambda_lcurve'] = lambda_lc.tolist()\n",
    "    gcv_dict[f'state{state+1}:gcv_lcurve'] = gcv_lc.tolist()\n",
    "    gcv_dict[f'state{state+1}:min_error_lambda'] = min_error_gcv_lambda\n",
    "    gcv_dict[f'state{state+1}:min_error_gcv'] = min_error_gcv_gcv\n",
    "    gcv_dict[f'state{state+1}:min_lambda'] = min_gcv_lambda\n",
    "    gcv_dict[f'state{state+1}:min_gcv'] = min_gcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if write_data:\n",
    "    # STORE LCURVE IN JSON FORMAT\n",
    "    filename_lc = 'VanderPol_trendfilter_lcurve_noise_' + str(noise_lvl).replace('.','d') + '.json'\n",
    "    filepath_lc = 'data_files/trendfilter/' + filename_lc\n",
    "    with open(filepath_lc, \"w\") as outfile:  \n",
    "        json.dump(lcurve_dict, outfile)  \n",
    "\n",
    "#     # STORE GCV IN JSON FORMAT\n",
    "#     filename_gcv = 'Lorenz63_trendfilter_gcv_noise_' + str(noise_lvl).replace('.','d') + '.json'\n",
    "#     filepath_gcv = 'data_files/trendfilter/' + filename_gcv\n",
    "#     with open(filepath_gcv, \"w\") as outfile:  \n",
    "#         json.dump(gcv_dict, outfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state1:residual -> <class 'list'>\n",
      "state1:regularizer -> <class 'list'>\n",
      "state1:res_corner -> <class 'float'>\n",
      "state1:reg_corner -> <class 'numpy.float64'>\n",
      "state1:res_min -> <class 'numpy.float64'>\n",
      "state1:reg_min -> <class 'numpy.float64'>\n",
      "state1:res_gcv -> <class 'float'>\n",
      "state1:reg_gcv -> <class 'numpy.float64'>\n",
      "state1:lambda_lc -> <class 'float'>\n",
      "state1:gcv_lc -> <class 'numpy.float64'>\n",
      "state2:residual -> <class 'list'>\n",
      "state2:regularizer -> <class 'list'>\n",
      "state2:res_corner -> <class 'float'>\n",
      "state2:reg_corner -> <class 'numpy.float64'>\n",
      "state2:res_min -> <class 'numpy.float64'>\n",
      "state2:reg_min -> <class 'numpy.float64'>\n",
      "state2:res_gcv -> <class 'float'>\n",
      "state2:reg_gcv -> <class 'numpy.float64'>\n",
      "state2:lambda_lc -> <class 'float'>\n",
      "state2:gcv_lc -> <class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "for key in lcurve_dict:\n",
    "    print(key, '->', type(lcurve_dict[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcurve_dict['state1:lambda_lc'] = float(lcurve_dict['state1:lambda_lc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
