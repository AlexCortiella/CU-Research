{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import numpy.linalg\n",
    "import numpy.matlib\n",
    "from numpy.linalg import norm\n",
    "import algorithms.tikhonov as tikhonov\n",
    "from scipy import interpolate\n",
    "from scipy import signal\n",
    "import csv   \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(221, 100)\n",
      "  Convergence criterion reached in 10 iterations.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-40a804ac46a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;31m#GCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtik_gcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtikhonov\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_lambdas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_lambdas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcv_lambda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtik_gcv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mmin_gcv_indx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcv_lambda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mmin_gcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcv_lambda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# LOAD DATA\n",
    "\n",
    "# 1) LOAD DYNAMICS AND TIME ARRAYS\n",
    "\n",
    "filepath = 'data_files/Lorenz63_dynamics.csv'\n",
    "dynamics = np.genfromtxt(filepath, delimiter=',')\n",
    "\n",
    "t = dynamics[0]\n",
    "data = dynamics[1:]\n",
    "n_states = int(data.shape[0] / 2)\n",
    "X = data[0:n_states]\n",
    "DX = data[n_states:]\n",
    "t_samples = len(t)\n",
    "\n",
    "noise_lvl = 0.001\n",
    "\n",
    "write_data = False\n",
    "\n",
    "## Select realization\n",
    "sample = 0\n",
    "\n",
    "##Range of lambdas\n",
    "lambda_min = 1e-16\n",
    "lambda_max = 1e1\n",
    "n_lambdas = 100\n",
    "\n",
    "#Vreate dictionary to store values\n",
    "lcurve_dict = {}\n",
    "gcv_dict = {}\n",
    "\n",
    "\n",
    "# LOAD OBSERVATION SAMPLES\n",
    "Y_samples = []\n",
    "\n",
    "for state in range(n_states):\n",
    "\n",
    "    filepath = 'data_files/Lorenz63_samples_noise_' + str(noise_lvl) +'_Y'+ str(state+1) + '.csv'\n",
    "    y = np.genfromtxt(filepath, delimiter=',')\n",
    "\n",
    "    Y_samples.append(y)\n",
    "\n",
    "n_samples = Y_samples[0].shape[0]\n",
    "\n",
    "################### DENOISING AND NUMERICAL DIFFERENTIATION - SMOOTHING SPLINES ###################\n",
    "# trim = int(np.floor(5 / 100 * t_samples))\n",
    "# tt_samples = t_samples - 2 * trim\n",
    "\n",
    "\n",
    "for state in range(n_states):\n",
    "\n",
    "    y = Y_samples[state][sample,:]\n",
    "\n",
    "    #L-CURVE\n",
    "    tik_flc = tikhonov.full_lcurve(y, lambda_min, lambda_max, n_lambdas = n_lambdas)\n",
    "    tik_path = tik_flc[0]\n",
    "    print(tik_path.shape)\n",
    "    res, reg = tik_flc[1]\n",
    "    error_path = np.zeros(tik_path.shape[1])\n",
    "    for i in range(tik_path.shape[1]):\n",
    "        error_path[i] = norm(tik_path[:,i] - X[state,:]) / norm(X[state,:])\n",
    "\n",
    "    min_indx_lc = np.argmin(error_path)\n",
    "    res_min = res[min_indx_lc]\n",
    "    reg_min = reg[min_indx_lc]\n",
    "\n",
    "    #Find corner point\n",
    "    tik_lc = tikhonov.lcurve_corner(y, lambda_min, lambda_max)\n",
    "    y_tik = tik_lc[0]\n",
    "    res_lc, reg_lc = tik_lc[3]\n",
    "    lambda_lc = tik_lc[1]\n",
    "\n",
    "    #GCV\n",
    "    tik_gcv = tikhonov.gcv(y, lambda_min, lambda_max, n_lambdas = n_lambdas)\n",
    "    lambdas, gcv_lambda = tik_gcv[1]\n",
    "    min_gcv_indx = np.argmin(gcv_lambda)\n",
    "    min_gcv = np.min(gcv_lambda)\n",
    "    min_gcv_lambda = lambdas[min_gcv_indx] \n",
    "\n",
    "    y_tik_path = tik_gcv[2]\n",
    "\n",
    "    error_path_gcv = np.zeros(y_tik_path.shape[1])\n",
    "    for i in range(y_tik_path.shape[1]):\n",
    "        error_path_gcv[i] = norm(y_tik_path[:,i] - X[state,:]) / norm(X[state,:])\n",
    "    min_indx_error_gcv = np.argmin(error_path_gcv) \n",
    "    min_error_gcv_gcv = gcv_lambda[min_indx_error_gcv]\n",
    "    min_error_gcv_lambda = lambdas[min_indx_error_gcv]\n",
    "\n",
    "    #Solve for optimal gcv lambda\n",
    "    tik_gcv_opt = tikhonov.tikhonov(y, lambd = min_gcv_lambda)\n",
    "    res_gcv, reg_gcv = tik_gcv_opt[1]\n",
    "\n",
    "    #Solve for optimal Lcurve lambda\n",
    "    tik_lc_opt = tikhonov.tikhonov(y, t, lambd = lambda_lc)\n",
    "    gcv_lc = ss_tik_opt[2][0]\n",
    "\n",
    "\n",
    "    plt.figure(figsize = (16,8))\n",
    "    plt.loglog(res, reg)\n",
    "    plt.loglog(res_min, reg_min,'ko')\n",
    "    plt.loglog(res_lc[-1], reg_lc[-1], 'ro')\n",
    "    plt.loglog(res_gcv, reg_gcv, 'bo')\n",
    "\n",
    "    lcurve_dict[f'state{state+1}:residual'] = res.tolist()\n",
    "    lcurve_dict[f'state{state+1}:regularizer'] = reg.tolist()\n",
    "    lcurve_dict[f'state{state+1}:res_corner'] = res_lc[-1]\n",
    "    lcurve_dict[f'state{state+1}:reg_corner'] = reg_lc[-1]\n",
    "    lcurve_dict[f'state{state+1}:res_min'] = res_min\n",
    "    lcurve_dict[f'state{state+1}:reg_min'] = reg_min\n",
    "    lcurve_dict[f'state{state+1}:res_gcv'] = res_gcv\n",
    "    lcurve_dict[f'state{state+1}:reg_gcv'] = reg_gcv\n",
    "\n",
    "    plt.figure(figsize = (16,8))\n",
    "    plt.semilogx(lambdas, gcv_lambda)\n",
    "    plt.semilogx(min_gcv_lambda, min_gcv, 'bo')\n",
    "    plt.semilogx(min_error_gcv_lambda, min_error_gcv_gcv, 'ko')\n",
    "    plt.semilogx(lambda_lc, gcv_lc, 'ro')\n",
    "\n",
    "    gcv_dict[f'state{state+1}:lambdas'] = lambdas.tolist()\n",
    "    gcv_dict[f'state{state+1}:gcv_func'] = gcv_lambda.tolist()\n",
    "    gcv_dict[f'state{state+1}:lambda_lcurve'] = lambda_lc.tolist()\n",
    "    gcv_dict[f'state{state+1}:gcv_lcurve'] = gcv_lc.tolist()\n",
    "    gcv_dict[f'state{state+1}:min_error_lambda'] = min_error_gcv_lambda\n",
    "    gcv_dict[f'state{state+1}:min_error_gcv'] = min_error_gcv_gcv\n",
    "    gcv_dict[f'state{state+1}:min_lambda'] = min_gcv_lambda\n",
    "    gcv_dict[f'state{state+1}:min_gcv'] = min_gcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "if write_data:\n",
    "    # STORE LCURVE IN JSON FORMAT\n",
    "    filename_lc = 'lcurve_' + str(noise_lvl) + '.json'\n",
    "    filepath_lc = 'data_files/tikhonov/' + filename_lc\n",
    "    with open(filepath_lc, \"w\") as outfile:  \n",
    "        json.dump(lcurve_dict, outfile)  \n",
    "\n",
    "    # STORE GCV IN JSON FORMAT\n",
    "    filename_gcv = 'gcv_' + str(noise_lvl) + '.json'\n",
    "    filepath_gcv = 'data_files/tikhonov/' + filename_gcv\n",
    "    with open(filepath_gcv, \"w\") as outfile:  \n",
    "        json.dump(gcv_dict, outfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
